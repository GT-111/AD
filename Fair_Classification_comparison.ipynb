{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.config_utils import get_config\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_data_set_original(dataset, config):\n",
    "    train_set, test_set = train_test_split(dataset, test_size=config['test_size'], random_state=config['random_state'])\n",
    "    return train_set, test_set\n",
    "\n",
    "def get_data_set_with_certain_group_excluded(sensitive_variable_name, sensitive_variable_map, original_dataset):\n",
    "    # return a dictionary of dataframes, each dataframe is a dataset with certain group excluded\n",
    "    # the key is the excluded group\n",
    "    result_dic = {}\n",
    "    for key, value in sensitive_variable_map.items():\n",
    "        train_set = original_dataset[original_dataset[sensitive_variable_name] == value] \n",
    "        #get not equal to value\n",
    "        test_set = original_dataset[original_dataset[sensitive_variable_name] != value]\n",
    "        result_dic[key] = {\n",
    "            'train_set': train_set,\n",
    "            'test_set': test_set\n",
    "        }\n",
    "    return result_dic\n",
    "\n",
    "def get_model(name, params):\n",
    "    if name == 'lr':\n",
    "        model = LogisticRegression(**params)\n",
    "    elif name == 'svm':\n",
    "        model = SVC(**params)\n",
    "    elif name == 'rf':\n",
    "        model = RandomForestClassifier(**params)\n",
    "    elif name == 'gb':\n",
    "        model = GradientBoostingClassifier(**params)\n",
    "    elif name == 'nn':\n",
    "        model = MLPClassifier(**params)\n",
    "    else:\n",
    "        raise ValueError('No such model')\n",
    "    return model\n",
    "\n",
    "def preprocess_data(features, config):\n",
    "    features = features.copy()\n",
    "    drop_columns = config['drop_columns']\n",
    "    # drop the columns\n",
    "    features = features.drop(drop_columns, axis=1)\n",
    "    # get the missing values threshold\n",
    "    missing_values_threshold = config['missing_values_threshold']\n",
    "    #calculate missing values ratio\n",
    "    missing_ratio = features.isnull().mean()\n",
    "    # print(f'missing_ratio: {missing_ratio}')\n",
    "    #retain the values which are less than the threshold\n",
    "    variables_to_be_retained = features.columns[missing_ratio <= missing_values_threshold]\n",
    "    features = features[variables_to_be_retained]\n",
    "    # The samplest way to fill missing numerical values is to fill them with 0\n",
    "    features = features.fillna(0)\n",
    "    # check if there are any null values\n",
    "    has_null_values = features.isnull().any().any()\n",
    "    # if has_null_values:\n",
    "    #     print(\"has null values.\")\n",
    "    # else:\n",
    "    #     print(\"has no null values.\")\n",
    "\n",
    "    string_columns = features.select_dtypes(include='object').columns\n",
    "    # print the variables that are numerical(not strings)\n",
    "    num_string_columns = len(string_columns)\n",
    "    # print(f\"String Columns in Dataframe are are listed below. There are {num_string_columns} colums in total.\")\n",
    "\n",
    "    # for col in string_columns:\n",
    "    #     print(col)\n",
    "\n",
    "    # drop the string columns\n",
    "    features = features.drop(string_columns, axis=1)\n",
    "    # One-Hot Encoding\n",
    "    features = pd.get_dummies(features)\n",
    "    # normalize\n",
    "    normalize_method = config['normalize_method']\n",
    "    if normalize_method == 'min_max':\n",
    "        features = (features - features.min()) / (features.max() - features.min())\n",
    "    elif normalize_method == 'z_score':\n",
    "        features = (features - features.mean()) / features.std()\n",
    "    else:\n",
    "        raise ValueError('No such normalize method')\n",
    "    # There maybe some identical columns in the dataset, so we need to remove them. (Maybe there are other ways to do this)\n",
    "    columns_with_null = features.columns[features.isnull().any()]\n",
    "\n",
    "    # Print the column names with null values\n",
    "    # print(\"Columns with null values:\")\n",
    "    # print(columns_with_null)\n",
    "    features.drop(columns_with_null, axis=1, inplace=True)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def train_and_evaluate(model, train_set, test_set, config):\n",
    "    target_variable = config['target_variable']\n",
    "    y_train = train_set[target_variable].copy()\n",
    "    y_test = test_set[target_variable].copy()\n",
    "    \n",
    "    y_train = y_train.map({0: 0, 1: 1, 8: 0})\n",
    "    y_test = y_test.map({0: 0, 1: 1, 8: 0})\n",
    "    \n",
    "    X_train = train_set.drop(columns=[target_variable])\n",
    "    # print(X_train.shape)\n",
    "    X_test = test_set.drop(columns=[target_variable])\n",
    "    # print(X_test.shape)\n",
    "    #feature_names, features_values\n",
    "    X_train = preprocess_data(X_train, config['preprocessing'])\n",
    "    X_test = preprocess_data(X_test, config['preprocessing'])\n",
    "    common_columns = X_train.columns.intersection(X_test.columns)\n",
    "    X_train = X_train[common_columns]\n",
    "    X_test = X_test[common_columns]\n",
    "    X_train_names, X_train_values = X_train.columns, X_train.values\n",
    "    X_test_names, X_test_values = X_test.columns, X_test.values\n",
    "    \n",
    "    model.fit(X_train_values, y_train)\n",
    "    y_pred = model.predict(X_test_values)\n",
    "    return y_pred, y_test, model\n",
    "\n",
    "def calculate_classification_metrics(model_name, y_true, y_pred_prob, metrics):\n",
    "    # Threshold 0,5 by default\n",
    "    y_pred = np.where(y_pred_prob >= 0.5, 1, 0)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Recall\n",
    "    sensitivity = recall_score(y_true, y_pred)\n",
    "\n",
    "    # Specificity\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "    # F1 Score\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # ROC AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # FPR FNR\n",
    "    false_positive_rate = fpr[1]\n",
    "    false_negative_rate = 1 - tpr[1]\n",
    "\n",
    "    # confusion_matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    metrics[model_name] = {\n",
    "        \"fpr_tpr\": (fpr, tpr),\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Sensitivity (Recall)\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"False Positive Rate\": false_positive_rate,\n",
    "        \"False Negative Rate\": false_negative_rate,\n",
    "        \"Confusion Matrix\": conf_matrix\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def metrics_to_df(metrics):\n",
    "    df = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "    df = df[['Accuracy', 'Sensitivity (Recall)', 'Specificity', 'F1 Score', 'ROC AUC', 'False Positive Rate', 'False Negative Rate']]\n",
    "    return df\n",
    "\n",
    "def plot_auc(metrics, tag):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for model_name, metric in metrics.items():\n",
    "        fpr, tpr = metric['fpr_tpr']\n",
    "        roc_auc = metric['ROC AUC']\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic {tag}')\n",
    "    plt.legend(loc='lower right')\n",
    "    path = os.path.join(\"pics\", f'roc_curve{tag}.png')\n",
    "    plt.savefig(path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/NACC.csv\n",
      "config/config_default.yaml\n",
      "{'target_variable': 'NACCALZD', 'test_size': 0.2, 'random_state': 42, 'model_dict': {'lr': {'C': 100, 'solver': 'saga'}, 'gb': {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 50, 'max_features': 0.3}, 'rf': {'n_estimators': 200, 'max_features': 'auto', 'max_depth': 6, 'criterion': 'entropy'}, 'svm': {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}, 'nn': {'hidden_layer_sizes': [128, 32], 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.05, 'learning_rate': 'adaptive'}}, 'preprocessing': {'drop_columns': ['NACCETPR', 'NACCALZP', 'PROBAD', 'PROBADIF', 'POSSAD', 'POSSADIF', 'NACCADMD'], 'missing_values_threshold': 0.2, 'normalize_method': 'min_max'}, 'protected_attributes': {'RACE': {'name': 'RACE', 'map': {'White': 1, 'black_or_African_American': 2, 'American_Indian_or_Alaska_Native': 3, 'Asian': 5}}, 'SEX': {'name': 'SEX', 'map': {'Male': 1, 'Female': 2}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gt/anaconda3/envs/tp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RACE White acc:0.9498404012767898 roc-auc:0.9453005660262073\n",
      "RACE black_or_African_American acc:0.9516806722689075 roc-auc:0.9464351173020528\n",
      "RACE American_Indian_or_Alaska_Native acc:0.9302325581395349 roc-auc:0.8934659090909092\n",
      "RACE Asian acc:0.8928571428571429 roc-auc:0.8959083469721767\n",
      "SEX Male acc:0.9347399411187438 roc-auc:0.9330342252505888\n",
      "SEX Female acc:0.9575098814229249 roc-auc:0.9515149623458508\n",
      "RACE White acc:0.9740082079343365 roc-auc:0.9684804223810872\n",
      "RACE black_or_African_American acc:0.9726890756302521 roc-auc:0.968475073313783\n",
      "RACE American_Indian_or_Alaska_Native acc:0.9534883720930233 roc-auc:0.9389204545454546\n",
      "RACE Asian acc:0.9642857142857143 roc-auc:0.9662847790507364\n",
      "SEX Male acc:0.9627085377821394 roc-auc:0.9579694173728706\n",
      "SEX Female acc:0.980566534914361 roc-auc:0.9761164299212867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gt/anaconda3/envs/tp/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RACE White acc:0.9131326949384405 roc-auc:0.9236128469618445\n",
      "RACE black_or_African_American acc:0.9201680672268907 roc-auc:0.9199046920821115\n",
      "RACE American_Indian_or_Alaska_Native acc:0.9302325581395349 roc-auc:0.953125\n",
      "RACE Asian acc:0.8839285714285714 roc-auc:0.8970540098199672\n",
      "SEX Male acc:0.879784102060844 roc-auc:0.89459861695883\n",
      "SEX Female acc:0.9357707509881423 roc-auc:0.9400286023982883\n",
      "RACE White acc:0.9612403100775194 roc-auc:0.9607399167902593\n",
      "RACE black_or_African_American acc:0.9621848739495799 roc-auc:0.9613728005865102\n",
      "RACE American_Indian_or_Alaska_Native acc:0.9069767441860465 roc-auc:0.9076704545454546\n",
      "RACE Asian acc:0.8928571428571429 roc-auc:0.8988543371522096\n",
      "SEX Male acc:0.94946025515211 roc-auc:0.9496860733776233\n",
      "SEX Female acc:0.9667325428194994 roc-auc:0.9665368965262842\n",
      "RACE White acc:0.9594163246694026 roc-auc:0.9588714470607187\n",
      "RACE black_or_African_American acc:0.9432773109243697 roc-auc:0.9433651026392963\n",
      "RACE American_Indian_or_Alaska_Native acc:0.9302325581395349 roc-auc:0.9232954545454546\n",
      "RACE Asian acc:0.9017857142857143 roc-auc:0.9124386252045825\n",
      "SEX Male acc:0.9460255152109912 roc-auc:0.9466481882687856\n",
      "SEX Female acc:0.9631093544137023 roc-auc:0.9633219642583524\n"
     ]
    }
   ],
   "source": [
    "# The path of NACC Dataset\n",
    "NACC_DATASET_PATH = os.path.join(\"data\", \"NACC.csv\")\n",
    "# The path of the Config file \n",
    "DATA_CONFIG_PATH = os.path.join(\"config\", \"config_default.yaml\")\n",
    "print(NACC_DATASET_PATH)\n",
    "print(DATA_CONFIG_PATH)\n",
    "config = get_config(DATA_CONFIG_PATH)\n",
    "NACC_dataset = pd.read_csv(NACC_DATASET_PATH, low_memory=False)\n",
    "\n",
    "models_dict = config['model_dict']\n",
    "protected_attributes = config['protected_attributes']\n",
    "print(config)\n",
    "#original \n",
    "\n",
    "metrics = {}\n",
    "per_class_metrics = {}\n",
    "\n",
    "for model_name, model_params in models_dict.items():\n",
    "    per_class_metrics[model_name]= {}\n",
    "    train_set, test_set = get_data_set_original(NACC_dataset, config)\n",
    "    model = get_model(model_name, model_params)\n",
    "    y_pred, y_test, model = train_and_evaluate(model=model, train_set= train_set, test_set=test_set, config=config)\n",
    "    calculate_classification_metrics(model_name=model_name, y_pred_prob=y_pred, y_true=y_test, metrics=metrics)\n",
    "    # for protected_attribute in protected_attributes:\n",
    "    #     per_class_metrics[model_name][protected_attribute] = {}\n",
    "    #     sensitive_variable_name = protected_attributes[protected_attribute]['name']\n",
    "    #     sensitive_variable_map = protected_attributes[protected_attribute]['map']\n",
    "    #     for k, v in sensitive_variable_map.items():\n",
    "    #         per_class_y_pred_prob = y_pred[test_set[protected_attribute] == v]\n",
    "    #         per_class_y_true = y_test[test_set[protected_attribute] == v]\n",
    "    #         per_class_y_pred_prob = np.where(per_class_y_pred_prob >= 0.5, 1, 0)\n",
    "    \n",
    "    #         # Accuracy\n",
    "    #         accuracy = accuracy_score(per_class_y_true, per_class_y_pred_prob)\n",
    "    #         # ROC AUC\n",
    "    #         fpr, tpr, thresholds = roc_curve(per_class_y_true, per_class_y_pred_prob)\n",
    "    #         roc_auc = auc(fpr, tpr)\n",
    "    #         print(f'{protected_attribute} {k} acc:{accuracy} roc-auc:{roc_auc}')\n",
    "plot_auc(metrics, tag='original')\n",
    "df = metrics_to_df(metrics)\n",
    "#save\n",
    "df.to_csv('original.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path of NACC Dataset\n",
    "NACC_DATASET_PATH = os.path.join(\"data\", \"NACC.csv\")\n",
    "# The path of the Config file \n",
    "DATA_CONFIG_PATH = os.path.join(\"config\", \"config_default.yaml\")\n",
    "print(NACC_DATASET_PATH)\n",
    "print(DATA_CONFIG_PATH)\n",
    "config = get_config(DATA_CONFIG_PATH)\n",
    "NACC_dataset = pd.read_csv(NACC_DATASET_PATH, low_memory=False)\n",
    "\n",
    "models_dict = config['model_dict']\n",
    "protected_attributes = config['protected_attributes']\n",
    "metrics = {}\n",
    "for protected_attribute in protected_attributes:\n",
    "    metrics[protected_attribute] = {}\n",
    "    dataset_dic = get_data_set_with_certain_group_excluded(protected_attributes[protected_attribute]['name'],\n",
    "                                                      protected_attributes[protected_attribute]['map'],\n",
    "                                                      NACC_dataset.copy())\n",
    "    for k, v in dataset_dic.items():\n",
    "        train_group = k\n",
    "        for model_name, model_params in models_dict.items():\n",
    "            train_set = v['train_set'].copy()\n",
    "            test_set = v['test_set'].copy()\n",
    "            model = get_model(model_name, model_params)\n",
    "            y_pred, y_test, model= train_and_evaluate(model=model, train_set= train_set, test_set=test_set, config=config)\n",
    "            calculate_classification_metrics(model_name=model_name, y_pred_prob=y_pred, y_true=y_test, metrics=metrics[protected_attribute])\n",
    "        plot_auc(metrics[protected_attribute], f'{protected_attribute}  {train_group}')\n",
    "        df = metrics_to_df(metrics[protected_attribute])\n",
    "        #save\n",
    "        df.to_csv(f'{train_group}.csv')\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
